{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FuIIBJkvuRZt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ],
      "metadata": {
        "id": "Qf2bWjPUuk9W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xmOJvB0upwK",
        "outputId": "aab6aba8-a415-4eb4-8f89-29bf5b50de22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size\n",
        "voc_size = 10000 # Hyperparameter"
      ],
      "metadata": {
        "id": "GCNb5ZTOvQgv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Hot Representation"
      ],
      "metadata": {
        "id": "Eb-muGVUvf5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_rep = [one_hot(words, voc_size) for words in sent]\n",
        "print(onehot_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-wlElu9vfJ7",
        "outputId": "436b995a-e16c-4257-b7f4-de1244ab4096"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9730, 2871, 7408, 6352], [9730, 2871, 7408, 8513], [9730, 6418, 7408, 6028], [3248, 4084, 2084, 4920, 6774], [3248, 4084, 2084, 4920, 4640], [4203, 9730, 705, 7408, 7403], [2399, 2584, 7869, 4920]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoder show the index of getting 1 for that particulr word"
      ],
      "metadata": {
        "id": "Fe2JvY1qvz_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding Represntation"
      ],
      "metadata": {
        "id": "9XxsVNtOwB91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "zzQeL7nYvzRd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-padding\n",
        "sent_length = 8 # Hyperparameter\n",
        "embedded_docs = pad_sequences(onehot_rep, padding=\"pre\", maxlen = sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyPxaGewwPMJ",
        "outputId": "db969893-f3f7-4992-f8e0-6fb7a25bec10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 9730 2871 7408 6352]\n",
            " [   0    0    0    0 9730 2871 7408 8513]\n",
            " [   0    0    0    0 9730 6418 7408 6028]\n",
            " [   0    0    0 3248 4084 2084 4920 6774]\n",
            " [   0    0    0 3248 4084 2084 4920 4640]\n",
            " [   0    0    0 4203 9730  705 7408 7403]\n",
            " [   0    0    0    0 2399 2584 7869 4920]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Dimensions\n",
        "dim = 10 # Hyperparameter , 10 because our sentence size is small\n",
        "\n",
        "model = Sequential()\n",
        "# Embedding layer act like word2vec and convert the vectors and 10 indicate how many feature you want in each vector\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile(\"adam\", \"mse\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gzn4a3tx6GI",
        "outputId": "eda46e82-747c-407f-c645-184c49d0c982"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'the glass of milk',\n",
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2mErEP50AF3",
        "outputId": "1d328dce-58a4-41fc-9351-ce76423d552e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 9730, 2871, 7408, 6352], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVhbXw_S0itX",
        "outputId": "165aa8d3-9d72-44b3-ba4d-a1737d485a40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02420756,  0.02306268,  0.04960282, -0.00854678, -0.0280973 ,\n",
              "         0.02012387, -0.03065536,  0.00460125,  0.00487161, -0.02155936],\n",
              "       [ 0.02420756,  0.02306268,  0.04960282, -0.00854678, -0.0280973 ,\n",
              "         0.02012387, -0.03065536,  0.00460125,  0.00487161, -0.02155936],\n",
              "       [ 0.02420756,  0.02306268,  0.04960282, -0.00854678, -0.0280973 ,\n",
              "         0.02012387, -0.03065536,  0.00460125,  0.00487161, -0.02155936],\n",
              "       [ 0.02420756,  0.02306268,  0.04960282, -0.00854678, -0.0280973 ,\n",
              "         0.02012387, -0.03065536,  0.00460125,  0.00487161, -0.02155936],\n",
              "       [ 0.03250447, -0.04320952,  0.04894124, -0.02071166,  0.0432817 ,\n",
              "         0.02149763,  0.00789299, -0.03937318, -0.0407189 ,  0.03598752],\n",
              "       [ 0.04454093,  0.04752607,  0.00800165,  0.01931251, -0.02689745,\n",
              "        -0.0047732 ,  0.03418643,  0.01288933,  0.0479283 ,  0.04072206],\n",
              "       [-0.01802851, -0.01537425,  0.04748876,  0.03294964,  0.00773482,\n",
              "         0.04409761,  0.0415936 , -0.01443747, -0.04364238, -0.02809385],\n",
              "       [-0.04852532, -0.03040657,  0.02802889, -0.03074342,  0.02139732,\n",
              "         0.0496775 , -0.03223697, -0.00713753,  0.04834798,  0.00119555]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-9vYKH-1AAf",
        "outputId": "c36f54dc-ef14-4ec2-ed7b-09c28cd08c8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.02420756  0.02306268  0.04960282 -0.00854678 -0.0280973   0.02012387\n",
            "  -0.03065536  0.00460125  0.00487161 -0.02155936]\n",
            " [ 0.02420756  0.02306268  0.04960282 -0.00854678 -0.0280973   0.02012387\n",
            "  -0.03065536  0.00460125  0.00487161 -0.02155936]\n",
            " [ 0.02420756  0.02306268  0.04960282 -0.00854678 -0.0280973   0.02012387\n",
            "  -0.03065536  0.00460125  0.00487161 -0.02155936]\n",
            " [ 0.02420756  0.02306268  0.04960282 -0.00854678 -0.0280973   0.02012387\n",
            "  -0.03065536  0.00460125  0.00487161 -0.02155936]\n",
            " [ 0.03250447 -0.04320952  0.04894124 -0.02071166  0.0432817   0.02149763\n",
            "   0.00789299 -0.03937318 -0.0407189   0.03598752]\n",
            " [ 0.04454093  0.04752607  0.00800165  0.01931251 -0.02689745 -0.0047732\n",
            "   0.03418643  0.01288933  0.0479283   0.04072206]\n",
            " [-0.01802851 -0.01537425  0.04748876  0.03294964  0.00773482  0.04409761\n",
            "   0.0415936  -0.01443747 -0.04364238 -0.02809385]\n",
            " [-0.04852532 -0.03040657  0.02802889 -0.03074342  0.02139732  0.0496775\n",
            "  -0.03223697 -0.00713753  0.04834798  0.00119555]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4dvcegi1T-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}