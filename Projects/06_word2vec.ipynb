{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]', ' ', paragraph)\n",
    "text = re.sub(r'\\s+' , ' ', text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d' , ' ' , text)\n",
    "text = re.sub(r'\\s+' , ' ', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['I', 'have', 'three', 'visions', 'for', 'India', '.'],\n",
       " ['In',\n",
       "  '3000',\n",
       "  'years',\n",
       "  'of',\n",
       "  'our',\n",
       "  'history',\n",
       "  ',',\n",
       "  'people',\n",
       "  'from',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'world',\n",
       "  'have',\n",
       "  'come',\n",
       "  'and',\n",
       "  'invaded',\n",
       "  'us',\n",
       "  ',',\n",
       "  'captured',\n",
       "  'our',\n",
       "  'lands',\n",
       "  ',',\n",
       "  'conquered',\n",
       "  'our',\n",
       "  'minds',\n",
       "  '.'],\n",
       " ['From',\n",
       "  'Alexander',\n",
       "  'onwards',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Greeks',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Turks',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Moguls',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Portuguese',\n",
       "  ',',\n",
       "  'the',\n",
       "  'British',\n",
       "  ',',\n",
       "  'the',\n",
       "  'French',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Dutch',\n",
       "  ',',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  'came',\n",
       "  'and',\n",
       "  'looted',\n",
       "  'us',\n",
       "  ',',\n",
       "  'took',\n",
       "  'over',\n",
       "  'what',\n",
       "  'was',\n",
       "  'ours',\n",
       "  '.'],\n",
       " ['Yet',\n",
       "  'we',\n",
       "  'have',\n",
       "  'not',\n",
       "  'done',\n",
       "  'this',\n",
       "  'to',\n",
       "  'any',\n",
       "  'other',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['We', 'have', 'not', 'conquered', 'anyone', '.'],\n",
       " ['We',\n",
       "  'have',\n",
       "  'not',\n",
       "  'grabbed',\n",
       "  'their',\n",
       "  'land',\n",
       "  ',',\n",
       "  'their',\n",
       "  'culture',\n",
       "  ',',\n",
       "  'their',\n",
       "  'history',\n",
       "  'and',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'enforce',\n",
       "  'our',\n",
       "  'way',\n",
       "  'of',\n",
       "  'life',\n",
       "  'on',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['Why', '?'],\n",
       " ['Because',\n",
       "  'we',\n",
       "  'respect',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'others.That',\n",
       "  'is',\n",
       "  'why',\n",
       "  'my',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'that',\n",
       "  'of',\n",
       "  'freedom',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'India',\n",
       "  'got',\n",
       "  'its',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'of',\n",
       "  'this',\n",
       "  'in',\n",
       "  '1857',\n",
       "  ',',\n",
       "  'when',\n",
       "  'we',\n",
       "  'started',\n",
       "  'the',\n",
       "  'War',\n",
       "  'of',\n",
       "  'Independence',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'this',\n",
       "  'freedom',\n",
       "  'that',\n",
       "  'we',\n",
       "  'must',\n",
       "  'protect',\n",
       "  'and',\n",
       "  'nurture',\n",
       "  'and',\n",
       "  'build',\n",
       "  'on',\n",
       "  '.'],\n",
       " ['If',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'free',\n",
       "  ',',\n",
       "  'no',\n",
       "  'one',\n",
       "  'will',\n",
       "  'respect',\n",
       "  'us',\n",
       "  '.'],\n",
       " ['My', 'second', 'vision', 'for', 'India', '’', 's', 'development', '.'],\n",
       " ['For',\n",
       "  'fifty',\n",
       "  'years',\n",
       "  'we',\n",
       "  'have',\n",
       "  'been',\n",
       "  'a',\n",
       "  'developing',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'time',\n",
       "  'we',\n",
       "  'see',\n",
       "  'ourselves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'are',\n",
       "  'among',\n",
       "  'the',\n",
       "  'top',\n",
       "  '5',\n",
       "  'nations',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'GDP',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'have',\n",
       "  'a',\n",
       "  '10',\n",
       "  'percent',\n",
       "  'growth',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'most',\n",
       "  'areas',\n",
       "  '.'],\n",
       " ['Our', 'poverty', 'levels', 'are', 'falling', '.'],\n",
       " ['Our',\n",
       "  'achievements',\n",
       "  'are',\n",
       "  'being',\n",
       "  'globally',\n",
       "  'recognised',\n",
       "  'today',\n",
       "  '.'],\n",
       " ['Yet',\n",
       "  'we',\n",
       "  'lack',\n",
       "  'the',\n",
       "  'self-confidence',\n",
       "  'to',\n",
       "  'see',\n",
       "  'ourselves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  ',',\n",
       "  'self-reliant',\n",
       "  'and',\n",
       "  'self-assured',\n",
       "  '.'],\n",
       " ['Isn', '’', 't', 'this', 'incorrect', '?'],\n",
       " ['I', 'have', 'a', 'third', 'vision', '.'],\n",
       " ['India', 'must', 'stand', 'up', 'to', 'the', 'world', '.'],\n",
       " ['Because',\n",
       "  'I',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'unless',\n",
       "  'India',\n",
       "  'stands',\n",
       "  'up',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  ',',\n",
       "  'no',\n",
       "  'one',\n",
       "  'will',\n",
       "  'respect',\n",
       "  'us',\n",
       "  '.'],\n",
       " ['Only', 'strength', 'respects', 'strength', '.'],\n",
       " ['We',\n",
       "  'must',\n",
       "  'be',\n",
       "  'strong',\n",
       "  'not',\n",
       "  'only',\n",
       "  'as',\n",
       "  'a',\n",
       "  'military',\n",
       "  'power',\n",
       "  'but',\n",
       "  'also',\n",
       "  'as',\n",
       "  'an',\n",
       "  'economic',\n",
       "  'power',\n",
       "  '.'],\n",
       " ['Both', 'must', 'go', 'hand-in-hand', '.'],\n",
       " ['My',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'was',\n",
       "  'to',\n",
       "  'have',\n",
       "  'worked',\n",
       "  'with',\n",
       "  'three',\n",
       "  'great',\n",
       "  'minds',\n",
       "  '.'],\n",
       " ['Dr.', 'Vikram', 'Sarabhai', 'of', 'the', 'Dept', '.'],\n",
       " ['of',\n",
       "  'space',\n",
       "  ',',\n",
       "  'Professor',\n",
       "  'Satish',\n",
       "  'Dhawan',\n",
       "  ',',\n",
       "  'who',\n",
       "  'succeeded',\n",
       "  'him',\n",
       "  'and',\n",
       "  'Dr.',\n",
       "  'Brahm',\n",
       "  'Prakash',\n",
       "  ',',\n",
       "  'father',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'material',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'was',\n",
       "  'lucky',\n",
       "  'to',\n",
       "  'have',\n",
       "  'worked',\n",
       "  'with',\n",
       "  'all',\n",
       "  'three',\n",
       "  'of',\n",
       "  'them',\n",
       "  'closely',\n",
       "  'and',\n",
       "  'consider',\n",
       "  'this',\n",
       "  'the',\n",
       "  'great',\n",
       "  'opportunity',\n",
       "  'of',\n",
       "  'my',\n",
       "  'life',\n",
       "  '.'],\n",
       " ['I', 'see', 'four', 'milestones', 'in', 'my', 'career']]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words(\"english\")]\n",
    "\n",
    "\n",
    "# training the model\n",
    "model = Word2Vec(sentences , min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-2.37049768e-03  3.59159475e-03 -2.05687201e-03 -2.02488140e-04\n  2.91478983e-03  4.46251500e-03 -3.51736834e-03  3.71137680e-03\n -3.74323362e-03  8.34909442e-05 -6.59592741e-04 -1.96701265e-03\n -2.51490448e-04  3.82423121e-03  1.78265478e-03  1.00194023e-03\n -3.12382705e-04  4.03741840e-03 -4.51243110e-03 -4.41473676e-03\n  4.07518260e-03  1.07259816e-03 -2.44068261e-03  1.50363555e-03\n  2.87181302e-03  2.99292989e-03 -5.10544109e-04  2.86463834e-03\n -4.47376777e-04  3.48855066e-03 -2.17673415e-03 -3.73444962e-03\n -2.90257856e-03  1.20776135e-03  4.63223178e-03 -1.34354911e-03\n -8.81893793e-04 -1.13241782e-03 -2.02459563e-03  8.37709638e-04\n  3.21800262e-03  4.48526675e-03  2.42803618e-03  2.67401617e-03\n  3.40144802e-03 -4.56826901e-03 -6.64956984e-04 -2.20240676e-03\n -1.34920422e-03  4.85410448e-03 -2.97503243e-03 -7.77763955e-04\n  4.13230155e-03  1.41379237e-03  3.73648293e-03 -4.87345038e-03\n -3.51771689e-03  1.21318677e-03 -6.04145229e-04  1.95409078e-03\n  3.43547482e-03  3.56482877e-03  3.30338441e-03 -3.20399529e-03\n -4.13170597e-03  4.62796394e-04 -3.61098349e-03  4.13264800e-03\n  4.27587796e-03  3.11914715e-03  2.27044499e-03 -1.87024416e-03\n -1.39206834e-03  3.18859098e-03 -1.17445146e-04 -1.58589298e-03\n  2.63197185e-03 -1.28958398e-03 -3.11381463e-03  2.21605165e-04\n -4.55145584e-03  1.99628691e-03  1.67453336e-03 -2.42864224e-03\n  7.67502119e-04 -2.76609533e-03  3.54386447e-03 -2.50594108e-03\n  3.40439525e-04  1.09482300e-03  4.33963723e-03  2.32985080e-03\n -3.93884815e-03  1.52780121e-05  4.88137535e-04 -3.80031788e-03\n -3.47241876e-03  1.64108537e-03 -5.17349872e-05  4.11847513e-03]\n"
     ]
    }
   ],
   "source": [
    "# Finding word vectors\n",
    "vector = model.wv[\"vision\"]\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar words\n",
    "similar = model.wv.most_similar('see')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('For', 0.34570425748825073),\n",
       " ('respects', 0.2660065293312073),\n",
       " ('areas', 0.2343364804983139),\n",
       " ('consider', 0.19423332810401917),\n",
       " ('’', 0.1811961531639099),\n",
       " ('Dutch', 0.1735914796590805),\n",
       " ('vision', 0.17036288976669312),\n",
       " ('years', 0.16762396693229675),\n",
       " ('onwards', 0.16491156816482544),\n",
       " ('falling', 0.1555272936820984)]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}